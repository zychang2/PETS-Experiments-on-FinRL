{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwrAr8vEmP2M"
   },
   "source": [
    "# Introduction\n",
    "1. In this tutorial, we will be tuning hyperparameters for Stable baselines3 models using Optuna.\n",
    "2. The default model hyperparamters may not be adequate for your custom portfolio or custom state-space. Reinforcement learning algorithms are sensitive to hyperparamters, hence tuning is an important step.\n",
    "3. Hyperparamters are tuned based on an objective, which needs to be maximized or minimized. Here we tuned our hyperparamters to maximize the Sharpe Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRF-7Vp5NCjU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#Installing FinRL\n",
    "%%capture\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LRJk36AZQGuh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#Installing Optuna\n",
    "%%capture\n",
    "!pip3 install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqOKn-VWNGt4",
    "outputId": "32e0f056-37ad-4af4-f0de-71bcce6e5878"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# matplotlib.use('Agg')\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "import optuna\n",
    "%matplotlib inline\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "# Changed finrl_meta to meta\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv as StockTradingEnv_numpy\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.agents.rllib.models import DRLAgent as DRLAgent_rllib\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "import joblib\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import ray\n",
    "from pprint import pprint\n",
    "\n",
    "# Not needed for local run\n",
    "# import sys\n",
    "# sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU is available!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    device = torch.device(\"cuda\")  # Set the device to GPU\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")  # Set the device to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z7_fCHS6NMx9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mDATA_SAVE_DIR):\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mDATA_SAVE_DIR)  \u001b[38;5;66;03m# datasets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mTRAINED_MODEL_DIR):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)  # datasets\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)  # trained_models\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)  # tensorboard_log\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)  # results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71P6jMlEpikl"
   },
   "source": [
    "## Collecting data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frT5V9lLOv9X",
    "outputId": "9d05910d-aa9c-4273-ecd3-33e4098eabbb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m TRAIN_START_DATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2009-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m TEST_END_DATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-10-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconfig_tickers\u001b[49m\u001b[38;5;241m.\u001b[39mDOW_30_TICKER:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Fetch data for each ticker\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     portfolio_raw_df \u001b[38;5;241m=\u001b[39m YahooDownloader(start_date\u001b[38;5;241m=\u001b[39mTRAIN_START_DATE,\n\u001b[1;32m     13\u001b[0m                                        end_date\u001b[38;5;241m=\u001b[39mTEST_END_DATE,\n\u001b[1;32m     14\u001b[0m                                        ticker_list\u001b[38;5;241m=\u001b[39m[ticker])\u001b[38;5;241m.\u001b[39mfetch_data()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Append the fetched DataFrame to the list\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config_tickers' is not defined"
     ]
    }
   ],
   "source": [
    "#Custom ticker list dataframe download\n",
    "# ticker_list = config_tickers.DOW_30_TICKER\n",
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-01',\n",
    "#                      ticker_list = ticker_list).fetch_data()\n",
    "\n",
    "df_list = []\n",
    "TRAIN_START_DATE = '2009-01-01'\n",
    "TEST_END_DATE = '2021-10-01'\n",
    "for ticker in config_tickers.DOW_30_TICKER:\n",
    "    # Fetch data for each ticker\n",
    "    portfolio_raw_df = YahooDownloader(start_date=TRAIN_START_DATE,\n",
    "                                       end_date=TEST_END_DATE,\n",
    "                                       ticker_list=[ticker]).fetch_data()\n",
    "    # Append the fetched DataFrame to the list\n",
    "    df_list.append(portfolio_raw_df)\n",
    "\n",
    "# Concatenate all DataFrames row-wise\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cntKg5nWO5qn",
    "outputId": "93a5b7cb-fc19-446b-da92-a43f070f6049"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureEngineer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#You can add technical indicators and turbulence factor to dataframe\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Just set the use_technical_indicator=True, use_vix=True and use_turbulence=True\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m fe \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureEngineer\u001b[49m(\n\u001b[1;32m      4\u001b[0m                     use_technical_indicator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m                     tech_indicator_list \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mINDICATORS,\n\u001b[1;32m      6\u001b[0m                     use_vix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                     use_turbulence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                     user_defined_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m processed \u001b[38;5;241m=\u001b[39m fe\u001b[38;5;241m.\u001b[39mpreprocess_data(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureEngineer' is not defined"
     ]
    }
   ],
   "source": [
    "#You can add technical indicators and turbulence factor to dataframe\n",
    "#Just set the use_technical_indicator=True, use_vix=True and use_turbulence=True\n",
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprocessed\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39mto_markdown())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed' is not defined"
     ]
    }
   ],
   "source": [
    "print(processed.head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5diXih4zPE6m"
   },
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(5)\n",
    "\n",
    "processed_full.to_csv('processed_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RrJiFbSPKE2",
    "outputId": "5ca01b3e-8e7d-4e78-8d3f-289b8f3f8674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "10353\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-05-01','2021-10-01')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ub4JTTRcPOel",
    "outputId": "432716f9-82ed-463b-c4ac-a0901fe5a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YiF95zXgPTsd"
   },
   "outputs": [],
   "source": [
    "#Defining the environment kwargs\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "# From: https://github.com/AI4Finance-Foundation/FinRL/issues/540\\\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,  # added argument\n",
    "    \"buy_cost_pct\": buy_cost_list,  # changed to list\n",
    "    \"sell_cost_pct\": sell_cost_list,  # changed to list\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "#Instantiate the training gym compatible environment\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "892NcZALPWHF",
    "outputId": "88d8958a-a9aa-4fbf-9338-c990f7829a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the training environment\n",
    "# Also instantiate our training gent\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3EwB1T8opX2o"
   },
   "outputs": [],
   "source": [
    "#Instantiate the trading environment\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOynTQluppye"
   },
   "source": [
    "## Tuning hyperparameters using Optuna\n",
    "1. Go to this [link](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/hyperparams_opt.py), you will find all possible hyperparamters to tune for all the models.\n",
    "2. For your model, grab those hyperparamters which you want to optimize and then return a dictionary of hyperparamters.\n",
    "3. There is a feature in Optuna called as hyperparamters importance, you can point out those hyperparamters which are important for tuning.\n",
    "4. By default Optuna use [TPESampler](https://www.youtube.com/watch?v=tdwgR1AqQ8Y) for sampling hyperparamters from the search space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_vojRvAsP2ja"
   },
   "outputs": [],
   "source": [
    "def sample_ddpg_params(trial:optuna.Trial):\n",
    "  # Size of the replay buffer\n",
    "  buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "  \n",
    "  return {\"buffer_size\": buffer_size,\n",
    "          \"learning_rate\":learning_rate,\n",
    "          \"batch_size\":batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_a2c_params(trial:optuna.Trial):\n",
    "    # learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)  # fix deprecation\n",
    "    n_steps = trial.suggest_categorical(\n",
    "        \"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
    "    )\n",
    "    # ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)  # fix deprecation\n",
    "    # vf_coef = trial.suggest_uniform(\"vf_coef\", 0, 1)\n",
    "    return {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_steps\": n_steps,\n",
    "        \"ent_coef\": ent_coef\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xL7LeLeWrj6H"
   },
   "outputs": [],
   "source": [
    "#Calculate the Sharpe ratio\n",
    "#This is our objective for tuning\n",
    "def calculate_sharpe(df):\n",
    "    df['daily_return'] = df['account_value'].pct_change(1)\n",
    "    if df['daily_return'].std() != 0:\n",
    "        sharpe = (252 ** 0.5) * df['daily_return'].mean()/ \\\n",
    "            df['daily_return'].std()\n",
    "        return sharpe\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCRy_kL648DM"
   },
   "source": [
    "## Callbacks\n",
    "1. The callback will terminate if the improvement margin is below certain point\n",
    "2. It will terminate after certain number of trial_number are reached, not before that\n",
    "3. It will hold its patience to reach the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingCallback:\n",
    "    def __init__(self, threshold: int, trial_number: int, patience: int):\n",
    "        \"\"\"\n",
    "        threshold:int tolerance for increase in sharpe ratio\n",
    "        trial_number: int Prune after minimum number of trials\n",
    "        patience: int patience for the threshold\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.trial_number = trial_number\n",
    "        self.patience = patience\n",
    "        self.cb_list = []  # Trials list for which threshold is reached\n",
    "\n",
    "    def __call__(self, study: optuna.study, frozen_trial: optuna.Trial):\n",
    "        # Setting the best value in the current trial\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "\n",
    "        # Checking if the minimum number of trials have pass\n",
    "        if frozen_trial.number > self.trial_number:\n",
    "            previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "            # Checking if the previous and current objective values have the same sign\n",
    "            if previous_best_value * study.best_value >= 0:\n",
    "                # Checking for the threshold condition\n",
    "                if abs(previous_best_value - study.best_value) < self.threshold:\n",
    "                    self.cb_list.append(frozen_trial.number)\n",
    "                    # If threshold is achieved for the patience amount of time\n",
    "                    if len(self.cb_list) > self.patience:\n",
    "                        print(\"The study stops now...\")\n",
    "                        print(\n",
    "                            \"With number\",\n",
    "                            frozen_trial.number,\n",
    "                            \"and value \",\n",
    "                            frozen_trial.value,\n",
    "                        )\n",
    "                        print(\n",
    "                            \"The previous and current best values are {} and {} respectively\".format(\n",
    "                                previous_best_value, study.best_value\n",
    "                            )\n",
    "                        )\n",
    "                        study.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2C with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys   \n",
    "\n",
    "os.makedirs(\"A2C_optuna_models\",exist_ok=True)\n",
    "\n",
    "def objective(trial: optuna.Trial):  # Optuna objective\n",
    "    hyperparameters = sample_a2c_params(trial)\n",
    "    model_a2c = agent.get_model(\"a2c\", model_kwargs=hyperparameters)  # TODO: Could try out self-implemented A2C\n",
    "    trained_model = agent.train_model(model=model_a2c, tb_log_name=\"a2c\", total_timesteps=10000)  # train stablebaselines3's A2C\n",
    "    trained_model.save('A2C_optuna_models/a2c_{}.pth'.format(trial.number))  # save model with trial number as ID\n",
    "    # clear_output(wait=True)  # This will keep only the last trial tested\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "        model=trained_model,\n",
    "        environment=e_trade_gym\n",
    "    )\n",
    "    sharpe = calculate_sharpe(df_account_value)\n",
    "\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(\"final_a2c_study__.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:08:38,145] A new study created in memory with name: a2c_study\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 9.069790423538583e-05, 'n_steps': 1024, 'ent_coef': 3.1968399196034683e-06}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:10:09,130] Trial 0 finished with value: 1.0467206287624573 and parameters: {'learning_rate': 9.069790423538583e-05, 'n_steps': 1024, 'ent_coef': 3.1968399196034683e-06}. Best is trial 0 with value: 1.0467206287624573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.0031987155943821507, 'n_steps': 1024, 'ent_coef': 0.00020312961670857716}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:11:41,778] Trial 1 finished with value: 1.2321234462758197 and parameters: {'learning_rate': 0.0031987155943821507, 'n_steps': 1024, 'ent_coef': 0.00020312961670857716}. Best is trial 1 with value: 1.2321234462758197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 2.38180503070213e-05, 'n_steps': 16, 'ent_coef': 0.004121293029638071}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 1600      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0.173     |\n",
      "|    learning_rate      | 2.38e-05  |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 83.4      |\n",
      "|    reward             | 1.2544177 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 6.32      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3551227.09\n",
      "total_reward: 2551227.09\n",
      "total_cost: 401478.64\n",
      "total_trades: 80949\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 101         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 3200        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | 0.0199      |\n",
      "|    learning_rate      | 2.38e-05    |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 87.5        |\n",
      "|    reward             | -0.11346094 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.37        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4800      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | -0.206    |\n",
      "|    learning_rate      | 2.38e-05  |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 129       |\n",
      "|    reward             | -0.408095 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 6400       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0.0473     |\n",
      "|    learning_rate      | 2.38e-05   |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -97.7      |\n",
      "|    reward             | 0.21759926 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 7.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 2.38e-05  |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -8.93     |\n",
      "|    reward             | 1.7986554 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.55      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 9600       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0.0205     |\n",
      "|    learning_rate      | 2.38e-05   |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 48.4       |\n",
      "|    reward             | -0.5039934 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.16       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:13:18,323] Trial 2 finished with value: 0.40917030757284817 and parameters: {'learning_rate': 2.38180503070213e-05, 'n_steps': 16, 'ent_coef': 0.004121293029638071}. Best is trial 1 with value: 1.2321234462758197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 5.2340048721427795e-05, 'n_steps': 64, 'ent_coef': 0.0005298666736139674}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 112        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 6400       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.1      |\n",
      "|    explained_variance | 0.153      |\n",
      "|    learning_rate      | 5.23e-05   |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 48.2       |\n",
      "|    reward             | 0.21873954 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.97       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:14:48,217] Trial 3 finished with value: 0.528719921300583 and parameters: {'learning_rate': 5.2340048721427795e-05, 'n_steps': 64, 'ent_coef': 0.0005298666736139674}. Best is trial 1 with value: 1.2321234462758197.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.009399914420398066, 'n_steps': 512, 'ent_coef': 0.00020993843801086698}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4911662.03\n",
      "total_reward: 3911662.03\n",
      "total_cost: 10391.64\n",
      "total_trades: 41792\n",
      "Sharpe: 0.835\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:16:19,541] Trial 4 finished with value: 1.5110648087592045 and parameters: {'learning_rate': 0.009399914420398066, 'n_steps': 512, 'ent_coef': 0.00020993843801086698}. Best is trial 4 with value: 1.5110648087592045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.36359209473364146, 'n_steps': 16, 'ent_coef': 2.3829547523593072e-08}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 1600      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.4     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.364     |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 77.7      |\n",
      "|    reward             | 1.1691    |\n",
      "|    std                | 235       |\n",
      "|    value_loss         | 8.41      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 3200        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.364       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 130         |\n",
      "|    reward             | -0.25453633 |\n",
      "|    std                | 388         |\n",
      "|    value_loss         | 13.3        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 4800        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | -1.55e-05   |\n",
      "|    learning_rate      | 0.364       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 38.2        |\n",
      "|    reward             | -0.37080386 |\n",
      "|    std                | 591         |\n",
      "|    value_loss         | 14.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 110         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 6400        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.364       |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -86.6       |\n",
      "|    reward             | -0.19986372 |\n",
      "|    std                | 1.11e+03    |\n",
      "|    value_loss         | 11.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -25.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.364     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 126       |\n",
      "|    reward             | 1.7903554 |\n",
      "|    std                | 751       |\n",
      "|    value_loss         | 54.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 110         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 9600        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.364       |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -6.1        |\n",
      "|    reward             | -0.08358457 |\n",
      "|    std                | 1.22e+03    |\n",
      "|    value_loss         | 2.17        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:17:51,089] Trial 5 finished with value: 1.3695975223072174 and parameters: {'learning_rate': 0.36359209473364146, 'n_steps': 16, 'ent_coef': 2.3829547523593072e-08}. Best is trial 4 with value: 1.5110648087592045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.001812349871305581, 'n_steps': 8, 'ent_coef': 8.265607234648155e-06}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 112        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 800        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.1      |\n",
      "|    explained_variance | -0.0311    |\n",
      "|    learning_rate      | 0.00181    |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 234        |\n",
      "|    reward             | 0.57526433 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 34.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 1600      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.00181   |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 224       |\n",
      "|    reward             | 4.2116585 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 47.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 118        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 2400       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.00181    |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 73.9       |\n",
      "|    reward             | -3.5629795 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 8.45       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 116           |\n",
      "|    iterations         | 400           |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 3200          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.00181       |\n",
      "|    n_updates          | 399           |\n",
      "|    policy_loss        | 142           |\n",
      "|    reward             | -0.0061449385 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 13.3          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 115        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.00181    |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 89.1       |\n",
      "|    reward             | -2.4857092 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 7.54       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 4800      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.00181   |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 202       |\n",
      "|    reward             | 0.8730149 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 29.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 5600     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.00181  |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 275      |\n",
      "|    reward             | 8.942954 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 58.4     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 114          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 6400         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.00181      |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 7.85         |\n",
      "|    reward             | -0.062054813 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 1.59         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 7200     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.00181  |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -83.4    |\n",
      "|    reward             | 9.002824 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.45     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.00181   |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 18.1      |\n",
      "|    reward             | 7.4695573 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 8800      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -0.000388 |\n",
      "|    learning_rate      | 0.00181   |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -138      |\n",
      "|    reward             | 1.7498525 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 13.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 9600        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.00181     |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.66        |\n",
      "|    reward             | -0.59496135 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.391       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:19:19,628] Trial 6 finished with value: 1.3627999357161382 and parameters: {'learning_rate': 0.001812349871305581, 'n_steps': 8, 'ent_coef': 8.265607234648155e-06}. Best is trial 4 with value: 1.5110648087592045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 356, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1364529.71\n",
      "total_reward: 364529.71\n",
      "total_cost: 1975.88\n",
      "total_trades: 6981\n",
      "Sharpe: 1.363\n",
      "=================================\n",
      "hit end!\n",
      "{'learning_rate': 0.004778133862873408, 'n_steps': 128, 'ent_coef': 0.006562192211340152}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2346458.10\n",
      "total_reward: 1346458.10\n",
      "total_cost: 54797.22\n",
      "total_trades: 50391\n",
      "Sharpe: 0.544\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:20:42,372] Trial 7 finished with value: 1.2668300270488502 and parameters: {'learning_rate': 0.004778133862873408, 'n_steps': 128, 'ent_coef': 0.006562192211340152}. Best is trial 4 with value: 1.5110648087592045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.014744459088243693, 'n_steps': 128, 'ent_coef': 2.510784660114704e-08}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:22:03,108] Trial 8 finished with value: 0.9096160921768621 and parameters: {'learning_rate': 0.014744459088243693, 'n_steps': 128, 'ent_coef': 2.510784660114704e-08}. Best is trial 4 with value: 1.5110648087592045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.022238665134707736, 'n_steps': 128, 'ent_coef': 0.04525524814651032}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3208457.03\n",
      "total_reward: 2208457.03\n",
      "total_cost: 3160.22\n",
      "total_trades: 54306\n",
      "Sharpe: 0.710\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:23:28,614] Trial 9 finished with value: 1.7751415667028998 and parameters: {'learning_rate': 0.022238665134707736, 'n_steps': 128, 'ent_coef': 0.04525524814651032}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.4579045629871961, 'n_steps': 32, 'ent_coef': 0.09498013326989069}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 121        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 3200       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -98.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.458      |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -1.17e+03  |\n",
      "|    reward             | 0.48748147 |\n",
      "|    std                | 1.48e+03   |\n",
      "|    value_loss         | 159        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 6400      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -144      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.458     |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 728       |\n",
      "|    reward             | 0.5252056 |\n",
      "|    std                | 1.53e+06  |\n",
      "|    value_loss         | 31.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 126        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 9600       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -155       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.458      |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -314       |\n",
      "|    reward             | -0.7407671 |\n",
      "|    std                | 1.01e+05   |\n",
      "|    value_loss         | 10.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:24:50,001] Trial 10 finished with value: 1.5154913501978873 and parameters: {'learning_rate': 0.4579045629871961, 'n_steps': 32, 'ent_coef': 0.09498013326989069}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.6911073279866081, 'n_steps': 32, 'ent_coef': 0.07807076488793632}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 3200       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -103       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.691      |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -921       |\n",
      "|    reward             | -0.6632277 |\n",
      "|    std                | 824        |\n",
      "|    value_loss         | 97.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 117         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 6400        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -120        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.691       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 81.7        |\n",
      "|    reward             | -0.14142121 |\n",
      "|    std                | 5.99e+03    |\n",
      "|    value_loss         | 2.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 114         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 9600        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -151        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.691       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.18e+03    |\n",
      "|    reward             | -0.64073396 |\n",
      "|    std                | 6.02e+05    |\n",
      "|    value_loss         | 91.3        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:26:18,524] Trial 11 finished with value: 1.4973116170530973 and parameters: {'learning_rate': 0.6911073279866081, 'n_steps': 32, 'ent_coef': 0.07807076488793632}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.10276422167929608, 'n_steps': 32, 'ent_coef': 0.06461742577600674}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4393603.03\n",
      "total_reward: 3393603.03\n",
      "total_cost: 23487.95\n",
      "total_trades: 49804\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 107         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 3200        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -48.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.103       |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -441        |\n",
      "|    reward             | -0.38010812 |\n",
      "|    std                | 14.3        |\n",
      "|    value_loss         | 99.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 107        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 6400       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -67.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.103      |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 355        |\n",
      "|    reward             | 0.11730957 |\n",
      "|    std                | 62.6       |\n",
      "|    value_loss         | 39.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 9600       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -90.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.103      |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 480        |\n",
      "|    reward             | -0.3485061 |\n",
      "|    std                | 327        |\n",
      "|    value_loss         | 39.7       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:27:48,825] Trial 12 finished with value: 1.4927361570680404 and parameters: {'learning_rate': 0.10276422167929608, 'n_steps': 32, 'ent_coef': 0.06461742577600674}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.037460050210520165, 'n_steps': 256, 'ent_coef': 0.006663008686116493}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:29:16,274] Trial 13 finished with value: 1.6431194022832425 and parameters: {'learning_rate': 0.037460050210520165, 'n_steps': 256, 'ent_coef': 0.006663008686116493}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.04131516139407045, 'n_steps': 256, 'ent_coef': 0.005879003863387715}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3496281.81\n",
      "total_reward: 2496281.81\n",
      "total_cost: 2337.04\n",
      "total_trades: 38845\n",
      "Sharpe: 0.728\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:30:44,742] Trial 14 finished with value: 1.434404789325061 and parameters: {'learning_rate': 0.04131516139407045, 'n_steps': 256, 'ent_coef': 0.005879003863387715}. Best is trial 9 with value: 1.7751415667028998.\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.0005721124989524309, 'n_steps': 256, 'ent_coef': 0.0011505406271831633}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:32:12,339] Trial 15 finished with value: 1.3206598711777402 and parameters: {'learning_rate': 0.0005721124989524309, 'n_steps': 256, 'ent_coef': 0.0011505406271831633}. Best is trial 9 with value: 1.7751415667028998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.0720661604820144, 'n_steps': 2048, 'ent_coef': 4.009097084190781e-05}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:33:38,234] Trial 16 finished with value: 1.7893212360303676 and parameters: {'learning_rate': 0.0720661604820144, 'n_steps': 2048, 'ent_coef': 4.009097084190781e-05}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 356, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1540799.98\n",
      "total_reward: 540799.98\n",
      "total_cost: 998.99\n",
      "total_trades: 4272\n",
      "Sharpe: 1.789\n",
      "=================================\n",
      "hit end!\n",
      "{'learning_rate': 0.11077319352350509, 'n_steps': 2048, 'ent_coef': 2.9511016700070576e-07}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3183461.96\n",
      "total_reward: 2183461.96\n",
      "total_cost: 226101.83\n",
      "total_trades: 69714\n",
      "Sharpe: 0.652\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:35:09,650] Trial 17 finished with value: 1.3579212893575994 and parameters: {'learning_rate': 0.11077319352350509, 'n_steps': 2048, 'ent_coef': 2.9511016700070576e-07}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.1313631722525307, 'n_steps': 2048, 'ent_coef': 3.515179870104018e-05}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:36:39,721] Trial 18 finished with value: 1.459772772250219 and parameters: {'learning_rate': 0.1313631722525307, 'n_steps': 2048, 'ent_coef': 3.515179870104018e-05}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.0007292444504090859, 'n_steps': 128, 'ent_coef': 4.978111945260601e-07}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5900295.27\n",
      "total_reward: 4900295.27\n",
      "total_cost: 216671.07\n",
      "total_trades: 65757\n",
      "Sharpe: 0.943\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:38:08,097] Trial 19 finished with value: 1.4578761421597068 and parameters: {'learning_rate': 0.0007292444504090859, 'n_steps': 128, 'ent_coef': 4.978111945260601e-07}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.020228108874944747, 'n_steps': 2048, 'ent_coef': 1.7087499197772204e-05}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:39:42,577] Trial 20 finished with value: 1.5274815175513323 and parameters: {'learning_rate': 0.020228108874944747, 'n_steps': 2048, 'ent_coef': 1.7087499197772204e-05}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.03354432122000949, 'n_steps': 256, 'ent_coef': 0.015038797027987558}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:41:10,529] Trial 21 finished with value: 1.486846644618596 and parameters: {'learning_rate': 0.03354432122000949, 'n_steps': 256, 'ent_coef': 0.015038797027987558}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.0760536710731251, 'n_steps': 512, 'ent_coef': 0.018450789051394325}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3413081.30\n",
      "total_reward: 2413081.30\n",
      "total_cost: 42965.41\n",
      "total_trades: 47559\n",
      "Sharpe: 0.819\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:42:37,190] Trial 22 finished with value: 1.6887648326819964 and parameters: {'learning_rate': 0.0760536710731251, 'n_steps': 512, 'ent_coef': 0.018450789051394325}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.20349866496274885, 'n_steps': 512, 'ent_coef': 7.24921025913154e-05}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "[I 2024-11-06 14:44:04,109] Trial 23 finished with value: 1.6260066771547579 and parameters: {'learning_rate': 0.20349866496274885, 'n_steps': 512, 'ent_coef': 7.24921025913154e-05}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.06812796382784457, 'n_steps': 512, 'ent_coef': 0.001266671862863341}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5333110.75\n",
      "total_reward: 4333110.75\n",
      "total_cost: 2806.67\n",
      "total_trades: 33536\n",
      "Sharpe: 0.943\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:45:33,214] Trial 24 finished with value: 1.3020355140487767 and parameters: {'learning_rate': 0.06812796382784457, 'n_steps': 512, 'ent_coef': 0.001266671862863341}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.008592159025154643, 'n_steps': 8, 'ent_coef': 0.018743417515056645}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 800       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.00859   |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 279       |\n",
      "|    reward             | 1.4657485 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 1600      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.00859   |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 107       |\n",
      "|    reward             | 3.2858884 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 9.6       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 2400      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -0.00117  |\n",
      "|    learning_rate      | 0.00859   |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 171       |\n",
      "|    reward             | -4.645365 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 31.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 3200       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.00859    |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 21.2       |\n",
      "|    reward             | 0.29869524 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.368      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.00859    |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 26.6       |\n",
      "|    reward             | -3.4456172 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 0.493      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4800      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.00859   |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 189       |\n",
      "|    reward             | 0.8537669 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 21.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5600     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.00859  |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 56.5     |\n",
      "|    reward             | 5.900373 |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 7.89     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 104          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 6400         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.00859      |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 53.2         |\n",
      "|    reward             | -0.019782105 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 2.89         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 7200     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.00859  |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -171     |\n",
      "|    reward             | 2.188979 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 19.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.00859  |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 135      |\n",
      "|    reward             | 6.386121 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 13.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 8800      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.00859   |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -48.5     |\n",
      "|    reward             | 1.4768764 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 104         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 9600        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.00859     |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -7.41       |\n",
      "|    reward             | -0.82239485 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:47:09,499] Trial 25 finished with value: 1.5583527224375198 and parameters: {'learning_rate': 0.008592159025154643, 'n_steps': 8, 'ent_coef': 0.018743417515056645}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.1878881903723904, 'n_steps': 64, 'ent_coef': 2.044250520221642e-06}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 6400     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.188    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -231     |\n",
      "|    reward             | 0.339887 |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 47.7     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:48:38,143] Trial 26 finished with value: 1.707410524917026 and parameters: {'learning_rate': 0.1878881903723904, 'n_steps': 64, 'ent_coef': 2.044250520221642e-06}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 356, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1550754.30\n",
      "total_reward: 550754.30\n",
      "total_cost: 998.97\n",
      "total_trades: 5340\n",
      "Sharpe: 1.707\n",
      "=================================\n",
      "hit end!\n",
      "{'learning_rate': 0.21428442513566318, 'n_steps': 64, 'ent_coef': 8.906276757349905e-07}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2702145.27\n",
      "total_reward: 1702145.27\n",
      "total_cost: 28612.67\n",
      "total_trades: 42276\n",
      "Sharpe: 0.592\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 6400      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.214     |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 16        |\n",
      "|    reward             | 1.1665299 |\n",
      "|    std                | 14.4      |\n",
      "|    value_loss         | 5.83      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:50:08,157] Trial 27 finished with value: 1.5002806008378098 and parameters: {'learning_rate': 0.21428442513566318, 'n_steps': 64, 'ent_coef': 8.906276757349905e-07}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.8926488060017259, 'n_steps': 64, 'ent_coef': 9.047331185197167e-08}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 105        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 6400       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | 18         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.893      |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 75.3       |\n",
      "|    reward             | 0.26836628 |\n",
      "|    std                | 2.44e+03   |\n",
      "|    value_loss         | 169        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:51:42,687] Trial 28 finished with value: 1.3383390191981641 and parameters: {'learning_rate': 0.8926488060017259, 'n_steps': 64, 'ent_coef': 9.047331185197167e-08}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "{'learning_rate': 0.001465603914067428, 'n_steps': 1024, 'ent_coef': 2.1776324009492536e-06}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
      "C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_53992\\1594191206.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
      "c:\\Users\\frank\\.conda\\envs\\m_env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3125653.92\n",
      "total_reward: 2125653.92\n",
      "total_cost: 211792.87\n",
      "total_trades: 66268\n",
      "Sharpe: 0.612\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 14:53:11,570] Trial 29 finished with value: 1.525426542844777 and parameters: {'learning_rate': 0.001465603914067428, 'n_steps': 1024, 'ent_coef': 2.1776324009492536e-06}. Best is trial 16 with value: 1.7893212360303676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# Create a study object and specify the direction as 'maximize'\n",
    "# As you want to maximize sharpe\n",
    "# Pruner stops not promising iterations\n",
    "# Use a pruner, else you will get error related to divergence of model\n",
    "# You can also use Multivariate samplere\n",
    "# sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=1234)\n",
    "study = optuna.create_study(\n",
    "    study_name='a2c_study',\n",
    "    direction='maximize',\n",
    "    sampler=sampler,\n",
    "    pruner=optuna.pruners.HyperbandPruner(),\n",
    ")\n",
    "logging_callback = LoggingCallback(threshold=1e-5, trial_number=5, patience=30)\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    catch=(ValueError,),\n",
    "    callbacks=[logging_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_a2c_study__.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, \"final_a2c_study__.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDPG with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys   \n",
    "\n",
    "os.makedirs(\"DDPG_optuna_models\",exist_ok=True)\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "  #Trial will suggest a set of hyperparamters from the specified range\n",
    "  hyperparameters = sample_ddpg_params(trial)\n",
    "  model_ddpg = agent.get_model(\"ddpg\",model_kwargs = hyperparameters )\n",
    "  #You can increase it for better comparison\n",
    "  trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "                                  tb_log_name=\"ddpg\" ,\n",
    "                             total_timesteps=50000)\n",
    "  trained_ddpg.save('models/ddpg_{}.pth'.format(trial.number))\n",
    "  clear_output(wait=True)\n",
    "  #For the given hyperparamters, determine the account value in the trading period\n",
    "  df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym)\n",
    "  #Calculate sharpe from the account value\n",
    "  sharpe = calculate_sharpe(df_account_value)\n",
    "\n",
    "  return sharpe\n",
    "\n",
    "#Create a study object and specify the direction as 'maximize'\n",
    "#As you want to maximize sharpe\n",
    "#Pruner stops not promising iterations\n",
    "#Use a pruner, else you will get error related to divergence of model\n",
    "#You can also use Multivariate samplere\n",
    "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(study_name=\"ddpg_study\",direction='maximize',\n",
    "                            sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "logging_callback = LoggingCallback(threshold=1e-5,patience=30,trial_number=5)\n",
    "#You can increase the n_trials for a better search space scanning\n",
    "study.optimize(objective, n_trials=30,catch=(ValueError,),callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sg7LRlHmj9GB",
    "outputId": "b089f7d6-7e92-44f1-b535-5ed127105366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_ddpg_study__.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, \"final_ddpg_study__.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVMue1-xuGHC",
    "outputId": "115d9f90-081f-4ef0-e687-2d06eea505fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters after tuning {'learning_rate': 0.0720661604820144, 'n_steps': 2048, 'ent_coef': 4.009097084190781e-05}\n",
      "Hyperparameters before tuning {'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n"
     ]
    }
   ],
   "source": [
    "#Get the best hyperparamters\n",
    "print('Hyperparameters after tuning',study.best_params)\n",
    "print('Hyperparameters before tuning',config.A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsZmMw0ykmYo",
    "outputId": "0da397f4-b412-49f5-aa93-34cdc4bcbf8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=16, state=TrialState.COMPLETE, values=[1.7893212360303676], datetime_start=datetime.datetime(2024, 11, 6, 14, 32, 12, 340339), datetime_complete=datetime.datetime(2024, 11, 6, 14, 33, 38, 233786), params={'learning_rate': 0.0720661604820144, 'n_steps': 2048, 'ent_coef': 4.009097084190781e-05}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=1.0, log=True, low=1e-05, step=None), 'n_steps': CategoricalDistribution(choices=(8, 16, 32, 64, 128, 256, 512, 1024, 2048)), 'ent_coef': FloatDistribution(high=0.1, log=True, low=1e-08, step=None)}, trial_id=16, value=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fETqKJj4uSi5"
   },
   "outputs": [],
   "source": [
    "# from stable_baselines3 import DDPG\n",
    "# tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=env_train)\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "tuned_model_a2c = A2C.load('A2C_optuna_models/a2c_{}.pth'.format(study.best_trial.number), env=env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgchX1LLuua-",
    "outputId": "00b50778-ae4a-49f8-c676-2d5286d899c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "#Trading period account value with tuned model\n",
    "df_account_value_tuned, df_actions_tuned = DRLAgent.DRL_prediction(\n",
    "    model=tuned_model_a2c, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  account_value\n",
      "0  2020-05-01   1.000000e+06\n",
      "1  2020-05-04   9.978485e+05\n",
      "2  2020-05-05   1.001751e+06\n",
      "3  2020-05-06   1.003632e+06\n",
      "4  2020-05-07   1.000501e+06\n",
      "            AAPL  AMGN  AXP  BA  CAT  CRM  CSCO  CVX  DIS   GS  ...  MRK  \\\n",
      "date                                                            ...        \n",
      "2020-05-01   100     0  100   0    0  100     0    0  100  100  ...    0   \n",
      "2020-05-04   100     0  100   0    0  100     0    0  100  100  ...    0   \n",
      "2020-05-05   100     0  100   0    0  100     0    0  100  100  ...    0   \n",
      "2020-05-06   100     0  100   0    0  100     0    0  100  100  ...    0   \n",
      "2020-05-07   100     0  100   0    0  100     0    0  100  100  ...    0   \n",
      "\n",
      "            MSFT  NKE   PG  TRV  UNH  V   VZ  WBA  WMT  \n",
      "date                                                    \n",
      "2020-05-01     0    0  100    0  100  0  100    0  100  \n",
      "2020-05-04     0    0  100    0  100  0  100    0  100  \n",
      "2020-05-05     0    0  100    0  100  0  100    0  100  \n",
      "2020-05-06     0    0  100    0  100  0  100    0  100  \n",
      "2020-05-07     0    0  100    0  100  0  100    0  100  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_account_value_tuned.head())\n",
    "print(df_actions_tuned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s5KNvVuvr2D",
    "outputId": "6a4e6933-84ca-4689-b8c3-042fc77e181c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.356834\n",
      "Cumulative returns     0.540800\n",
      "Annual volatility      0.180128\n",
      "Sharpe ratio           1.789321\n",
      "Calmar ratio           3.765003\n",
      "Stability              0.965409\n",
      "Max drawdown          -0.094777\n",
      "Omega ratio            1.360814\n",
      "Sortino ratio          2.816772\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.023460\n",
      "Daily value at risk   -0.021415\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Backtesting with our pruned model\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_tuned = backtest_stats(account_value=df_account_value_tuned)\n",
    "perf_stats_all_tuned = pd.DataFrame(perf_stats_all_tuned)\n",
    "perf_stats_all_tuned.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_tuned_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuGaI9lSvvVD",
    "outputId": "7e72920e-84e5-486f-e7ce-747d282783d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -2.12     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 52.7      |\n",
      "|    reward             | 0.1687497 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.45      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -32.4     |\n",
      "|    reward             | -0.533331 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 116         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.10794261 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 24.9        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 57.3     |\n",
      "|    reward             | 2.16262  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 864       |\n",
      "|    reward             | 5.0900807 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 404       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -0.284     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 154        |\n",
      "|    reward             | -2.1725876 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 15.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -69.1      |\n",
      "|    reward             | 0.49733678 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -8.82e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 130       |\n",
      "|    reward             | -2.364106 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 19.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 162       |\n",
      "|    reward             | 0.2943332 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 18.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | -0.3454983 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | -0.0552    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -281       |\n",
      "|    reward             | -3.8408964 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 57.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 116       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | -0.0985   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -48.7     |\n",
      "|    reward             | 1.3741683 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 6.01      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 116        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0.00341    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 211        |\n",
      "|    reward             | -5.6828947 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 35         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -0.263    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 36.2      |\n",
      "|    reward             | 1.2113181 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.03      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 117      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | -0.039   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -34      |\n",
      "|    reward             | 9.161701 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 5.14     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -68.1      |\n",
      "|    reward             | -1.5109233 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.13       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -229      |\n",
      "|    reward             | 0.6852173 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 113       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | -0.0302   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 38.5      |\n",
      "|    reward             | 4.8058734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.64      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 117        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -47.5      |\n",
      "|    reward             | -1.3378667 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 118       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -174      |\n",
      "|    reward             | 1.2601422 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Now train with not tuned hyperaparameters\n",
    "#Default config.ddpg_PARAMS\n",
    "# non_tuned_model_ddpg = agent.get_model(\"ddpg\",model_kwargs = config.DDPG_PARAMS )\n",
    "# trained_ddpg = agent.train_model(model=non_tuned_model_ddpg, \n",
    "#                              tb_log_name='ddpg',\n",
    "#                              total_timesteps=50000)\n",
    "non_tuned_model_a2c = agent.get_model(\"a2c\", model_kwargs=config.A2C_PARAMS)\n",
    "trained_a2c = agent.train_model(model=non_tuned_model_a2c, tb_log_name='a2c', total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZbEYRQ1wBeC",
    "outputId": "c2aacb1f-9fc1-4816-c15a-da512df2b2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFdB4YM3wh0m",
    "outputId": "e31ca771-bf0f-4f5c-d385-839dfa215450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.490339\n",
      "Cumulative returns     0.759897\n",
      "Annual volatility      0.253207\n",
      "Sharpe ratio           1.707331\n",
      "Calmar ratio           3.534638\n",
      "Stability              0.896093\n",
      "Max drawdown          -0.138724\n",
      "Omega ratio            1.324939\n",
      "Sortino ratio          2.646543\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.992514\n",
      "Daily value at risk   -0.030186\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Backtesting for not tuned hyperparamters\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "# perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "12fxdvUZwi_W",
    "outputId": "56a25b27-dd6c-4620-acf1-76e68f252f32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          1.0467206287624573,
          1.2321234462758197,
          0.40917030757284817,
          0.528719921300583,
          1.5110648087592045,
          1.3695975223072174,
          1.3627999357161382,
          1.2668300270488502,
          0.9096160921768621,
          1.7751415667028998,
          1.5154913501978873,
          1.4973116170530973,
          1.4927361570680404,
          1.6431194022832425,
          1.434404789325061,
          1.3206598711777402,
          1.7893212360303676,
          1.3579212893575994,
          1.459772772250219,
          1.4578761421597068,
          1.5274815175513323,
          1.486846644618596,
          1.6887648326819964,
          1.6260066771547579,
          1.3020355140487767,
          1.5583527224375198,
          1.707410524917026,
          1.5002806008378098,
          1.3383390191981641,
          1.525426542844777
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          1.0467206287624573,
          1.2321234462758197,
          1.2321234462758197,
          1.2321234462758197,
          1.5110648087592045,
          1.5110648087592045,
          1.5110648087592045,
          1.5110648087592045,
          1.5110648087592045,
          1.7751415667028998,
          1.7751415667028998,
          1.7751415667028998,
          1.7751415667028998,
          1.7751415667028998,
          1.7751415667028998,
          1.7751415667028998,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676,
          1.7893212360303676
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#You can see with trial, our sharpe ratio is increasing\n",
    "#Certainly you can afford more number of trials for further optimization\n",
    "from optuna.visualization import plot_optimization_history\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_TUF2GvAx6-k"
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "2jkqeSUIyCT0",
    "outputId": "531590bb-e10c-4a96-b1d7-af57ff166030"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "ent_coef (FloatDistribution): 0.16427324767456444<extra></extra>",
          "learning_rate (FloatDistribution): 0.2372645510095233<extra></extra>",
          "n_steps (CategoricalDistribution): 0.5984622013159123<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.16",
          "0.24",
          "0.60"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.16427324767456444,
          0.2372645510095233,
          0.5984622013159123
         ],
         "y": [
          "ent_coef",
          "learning_rate",
          "n_steps"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Hyperparamters importance\n",
    "#Ent_coef is the most important\n",
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAD0MIAWukB9"
   },
   "source": [
    "## Further works\n",
    "\n",
    "1.   You can tune more critical hyperparameters\n",
    "2.   Multi-objective hyperparameter optimization using Optuna. Here we can maximize Sharpe and simultaneously minimize Volatility in our account value to tune our hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "_edBJqB8yEDr",
    "outputId": "2bf34851-7038-4341-b3cb-de7a85608c78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "a2c_study",
         "type": "scatter",
         "x": [
          0.40917030757284817,
          0.42311122604211604,
          0.4370521445113839,
          0.4509930629806518,
          0.46493398144991965,
          0.4788748999191875,
          0.49281581838845545,
          0.5067567368577233,
          0.5206976553269912,
          0.534638573796259,
          0.5485794922655269,
          0.5625204107347948,
          0.5764613292040627,
          0.5904022476733306,
          0.6043431661425984,
          0.6182840846118662,
          0.6322250030811342,
          0.6461659215504021,
          0.6601068400196699,
          0.6740477584889377,
          0.6879886769582056,
          0.7019295954274736,
          0.7158705138967414,
          0.7298114323660092,
          0.7437523508352772,
          0.7576932693045451,
          0.7716341877738129,
          0.7855751062430808,
          0.7995160247123487,
          0.8134569431816165,
          0.8273978616508844,
          0.8413387801201523,
          0.8552796985894202,
          0.869220617058688,
          0.8831615355279558,
          0.8971024539972238,
          0.9110433724664917,
          0.9249842909357595,
          0.9389252094050273,
          0.9528661278742954,
          0.9668070463435632,
          0.980747964812831,
          0.9946888832820988,
          1.0086298017513669,
          1.0225707202206347,
          1.0365116386899025,
          1.0504525571591703,
          1.0643934756284383,
          1.0783343940977062,
          1.092275312566974,
          1.106216231036242,
          1.1201571495055098,
          1.1340980679747776,
          1.1480389864440455,
          1.1619799049133135,
          1.1759208233825813,
          1.1898617418518491,
          1.203802660321117,
          1.217743578790385,
          1.2316844972596528,
          1.2456254157289206,
          1.2595663341981884,
          1.2735072526674565,
          1.2874481711367243,
          1.301389089605992,
          1.3153300080752601,
          1.329270926544528,
          1.3432118450137958,
          1.3571527634830636,
          1.3710936819523316,
          1.3850346004215994,
          1.3989755188908672,
          1.412916437360135,
          1.4268573558294029,
          1.440798274298671,
          1.4547391927679387,
          1.4686801112372065,
          1.4826210297064744,
          1.4965619481757424,
          1.5105028666450102,
          1.524443785114278,
          1.538384703583546,
          1.5523256220528139,
          1.5662665405220817,
          1.5802074589913495,
          1.5941483774606175,
          1.6080892959298854,
          1.6220302143991532,
          1.635971132868421,
          1.649912051337689,
          1.6638529698069568,
          1.6777938882762247,
          1.6917348067454925,
          1.7056757252147605,
          1.7196166436840283,
          1.7335575621532961,
          1.7474984806225642,
          1.761439399091832,
          1.7753803175610998,
          1.7893212360303676
         ],
         "y": [
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.03333333333333333,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.06666666666666667,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.1,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.13333333333333333,
          0.16666666666666666,
          0.16666666666666666,
          0.2,
          0.2,
          0.2,
          0.23333333333333334,
          0.26666666666666666,
          0.3,
          0.3,
          0.4,
          0.4,
          0.4,
          0.4,
          0.4,
          0.43333333333333335,
          0.43333333333333335,
          0.5,
          0.5,
          0.5666666666666667,
          0.6333333333333333,
          0.7,
          0.7666666666666667,
          0.7666666666666667,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8333333333333334,
          0.8666666666666667,
          0.8666666666666667,
          0.8666666666666667,
          0.9,
          0.9,
          0.9333333333333333,
          0.9333333333333333,
          0.9333333333333333,
          0.9333333333333333,
          0.9666666666666667,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Empirical Distribution Function Plot"
        },
        "xaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Cumulative Probability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXTgG1yvgeyq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinRL_Hyperparameter tuning using Optuna",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "finrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
